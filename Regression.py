# -*- coding: utf-8 -*-
"""code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tnBQDBQ4FvN3qUJL7iHTcIVYRBaf3mfY
"""

import pandas as pd
import numpy as np
from sklearn.decomposition import PCA
import seaborn as sns
from sklearn import linear_model
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest
from sklearn.manifold import TSNE
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn import model_selection
from sklearn.model_selection import cross_val_score
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
from sklearn import tree
from sklearn import svm

def preprocess():
  """
  Returns a pre-processed Numpy array with the X and and y representing the feautures after PCA and
  the output values respectively.


  """
  df = pd.read_csv("communities.data",header=None)
  df = df._get_numeric_data()
  df = df.drop([0,4],axis = 1)
  dfs = np.split(df,[-1],axis=1)
  X = dfs[0]
  y = dfs[1]
  X=pd.DataFrame.to_numpy(X)
  y=pd.DataFrame.to_numpy(y)
  pca = PCA(0.9) # Keeping the features which incorporate 90 percent variance of the data.
  pca.fit(X)
  X = pca.transform(X)
  return X,y

def makeScorers():
  """
  Creates Scores for the evaluation metrics used. These will be used for calculating the cross validations scores.


  """
  mae=metrics.make_scorer(metrics.mean_absolute_error)
  mse=metrics.make_scorer(metrics.mean_squared_error)
  r2=metrics.make_scorer(metrics.r2_score)
  return mse,mae,r2

def LR(X,y):
  """
  Runs Linear Regression on the data and prints the average cross validation score(K=5) for
  all the metrics  
  

  """


  scores=makeScorers()
  clf=LinearRegression()
  # clf.fit(X_train,y_train)
  # y_pred=clf.predict(X_test)
  print("MSE= ",np.average(cross_val_score(clf,X,y,cv=5,scoring=scores[0])))
  print("MAE= ",np.average(cross_val_score(clf,X,y,cv=5,scoring=scores[1])))
  print("R2= ",np.average(cross_val_score(clf,X,y,cv=5,scoring=scores[2])))
  # print(metrics.mean_squared_error(y_test, y_pred))
  # print(metrics.mean_absolute_error(y_test, y_pred))
  # print(metrics.r2_score(y_test, y_pred))

def runLR():

  """
    Call this to run the Linear Regression Model

  """
  X,y=preprocess()
  LR(X,y)

def residualLR():
  """
  Plots the Residual plots of Linear Regression
  

  """
  X,y=preprocess()
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,shuffle=True)
  clf=LinearRegression()
  clf.fit(X_train,y_train)
  ypred=clf.predict(X_test)
  res=ypred-y_test # Calculating residue
  # res=residualLR()
  plt.figure(50)
  plt.scatter(np.arange(1,y_test.shape[0]+1),res)
  plt.xlabel("Number of samples")
  plt.ylabel("Residual Value")
  plt.savefig("ResidualLR.png")
  return res




def Polynomial(X,y):
  """
  Runs Polynomial Regression on the data and prints the average cross validation score(K=5) for
  all the metrics  
  

  """
  scores=makeScorers()
  X=np.sign(X) * (np.abs(X)) ** (1 / 2) # making the features to sqrt(features).
  poly = PolynomialFeatures(2,interaction_only=True)
  X=poly.fit_transform(X) # Making a polynomial transform of degree 2.
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,shuffle=True)
  clf=LinearRegression() # performing Linear Regression after polynomial transform.
  print("MSE= ",np.average(cross_val_score(clf,X,y,cv=5,scoring=scores[0])))
  print("MAE= ",np.average(cross_val_score(clf,X,y,cv=5,scoring=scores[1])))
  print("R2= ",np.average(cross_val_score(clf,X,y,cv=5,scoring=scores[2])))

def runPoly():

  """
    Call this to run the Polynomial Regression  Model

  """
  X,y=preprocess()
  Polynomial(X,y)

def polyReasoning():
  """
  Plots the scatterplot with and without square-rooting the top PCA component. For analysis purposes.

  """
  df = pd.read_csv("communities.data",header=None)
  df = df._get_numeric_data()
  df = df.drop([0,4],axis = 1)
  dfs = np.split(df,[-1],axis=1)
  X = dfs[0]
  y = dfs[1]
  X=pd.DataFrame.to_numpy(X)
  y=pd.DataFrame.to_numpy(y)
  pca = PCA(n_components=2)
  pca.fit(X)
  X = pca.transform(X)
  c1=X[:,0]
  c2=X[:,1]
  c1=c1
  plt.figure(0)
  plt.scatter(c1,y)
  plt.xlabel("Top Component of PCA")
  plt.ylabel("Output")
  plt.savefig("Before_root.png")
  c1=c1**0.5  # Taking square root of the feature
  plt.figure(1)
  plt.scatter(c1,y)
  plt.xlabel("Top Component of PCA")
  plt.ylabel("Output")
  plt.savefig("After_root.png")


def Lasso(X,y):

  """
  Runs the Lasso Regression on the data with the best hyper parameter setting.


  """
  scores=makeScorers()
  clf=linear_model.Lasso(alpha=0.001)
  print("MSE= ",np.average(cross_val_score(clf,X,y,cv=5,scoring=scores[0])))
  print("MAE= ",np.average(cross_val_score(clf,X,y,cv=5,scoring=scores[1])))
  print("R2= ",np.average(cross_val_score(clf,X,y,cv=5,scoring=scores[2])))

def runLasso():

  """
    Call this to run the Lasso Model

  """
  X,y=preprocess()
  Lasso(X,y)

def LassoTuning():
  """

  Plots and saves the error metric with respect to the regularization parameter. Used for Grid Search


  """


  X,y=preprocess()
  scores=makeScorers()
  arr=[]
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
  for alphas in [0.0001,0.001,0.01,0.1,1]:
    clf=linear_model.Lasso(alpha=alphas)
    clf.fit(X_train,y_train)
    ypred=clf.predict(X_test)
    arr.append(metrics.mean_squared_error(ypred,y_test)) # Storing the erors for corresponding alpha for plotting.
    # print(np.sum(clf.coef_!=0),np.average(cross_val_score(clf,X,y,cv=5,scoring=scores[0])))
    # arr.append()
  plt.figure(30)
  plt.plot(['0.0001','0.001','0.01','0.1','1'],arr)
  plt.xlabel("Lasso Regularization Parameter")
  plt.ylabel("MSE Error")
  plt.savefig("LassoExplode.png")

def Ridge(X,y):
  """
  Performs Ridge Regression with the optimum set of hyperparameters.
  


  """


  scores=makeScorers()
  clf=linear_model.Ridge(alpha=1)
  print("MSE= ",np.average(cross_val_score(clf,X,y,cv=5,scoring=scores[0])))
  print("MAE= ",np.average(cross_val_score(clf,X,y,cv=5,scoring=scores[1])))
  print("R2= ",np.average(cross_val_score(clf,X,y,cv=5,scoring=scores[2])))

def runRidge():

  """
    Call this to run the Ridge Model

  """
  X,y=preprocess()
  Ridge(X,y)

def ridgePlot():

  """
  Plots and saves the MSE error metric with respect to the regularization parameter. Used for Grid Search



  """
  X,y=preprocess()
  scores=makeScorers()
  arr=[]
  for alphas in [0.0001,0.001,0.01,0.1,1,10,100,1000]:
    # print("Alpha= ",alphas)
    clf=linear_model.Ridge(alpha=alphas)
    arr.append(np.average(cross_val_score(clf,X,y,cv=5,scoring=scores[0])))# Storing the erors for corresponding alpha for plotting.
  plt.figure(20)
  plt.plot(['0.0001','0.001','0.01','0.1','1','10','100','1000'],arr)
  plt.xlabel("Regularization Parameter")
  plt.ylabel("MSE")
  plt.savefig("RidgePlot.png")


def ElasticNet(X,y):
  """
  Runs the elasticNet algorithm with the optimum hyperparameters


  """


  scores=makeScorers()
  clf=linear_model.ElasticNet(l1_ratio=0.6,alpha=0.0001)
  print("MSE= ",np.average(cross_val_score(clf,X,y,cv=5,scoring=scores[0])))
  print("MAE= ",np.average(cross_val_score(clf,X,y,cv=5,scoring=scores[1])))
  print("R2= ",np.average(cross_val_score(clf,X,y,cv=5,scoring=scores[2])))

def runElasticNet():


  """
    Call this to run the ElasticNet Model

  """
  X,y=preprocess()
  ElasticNet(X,y)

def ElasticTuning():
  """
  Plots and saves the MSE error metric with respect to the regularization parameter. Used for Grid Search

  """
  X,y=preprocess()
  scores=makeScorers()
  arr=[]
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
  for ratios in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:
    clf=linear_model.ElasticNet(l1_ratio=ratios,alpha=0.001)
    clf.fit(X_train,y_train)
    ypred=clf.predict(X_test)
    arr.append(metrics.mean_squared_error(ypred,y_test))# Storing the l1_ratios for corresponding alpha for plotting.
  plt.figure(10)
  plt.plot([0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],arr)
  plt.xlabel("Elastic Regularization Parameter")
  plt.ylabel("MSE Error")

def supportVectorRegressor(X,y,kernel='linear',C=1):
  """

  Runs the SVR algorithm with the optimum hyper parameter settings and Linear Kernel with C=1

  """


  scores=makeScorers()
  clf =svm.SVR(kernel=kernel,C=C)
  y=np.reshape(y,(y.shape[0],))
  av_mse=np.average(cross_val_score(clf,X,y,cv=5,scoring=scores[0]))
  av_mae=np.average(cross_val_score(clf,X,y,cv=5,scoring=scores[1]))
  av_r2=np.average(cross_val_score(clf,X,y,cv=5,scoring=scores[2]))
  return av_mse,av_mae,av_r2

def runSVM():

  """
    Call this to run the SVM Model

  """
  X,y=preprocess()
  print(supportVectorRegressor(X,y))






runLR()
runLasso()
runPoly()
runRidge()
runSVM()
runElasticNet()
ridgePlot()
residualLR()
ElasticTuning()
LassoTuning()
polyReasoning()













